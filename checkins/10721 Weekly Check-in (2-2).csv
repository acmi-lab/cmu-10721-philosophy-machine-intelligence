Name (First + Last) ,Question 1,Question 2,Question 3
Michael Feffer,Pitts and McCulloch’s paper contains diagrams and equations eerily similar to those pertaining to modern (artificial) neural nets used in deep learning. How are they similar? How are they different? Are these similarities and differences important? Why or why not?,"Wiener writes that “Cybernetics takes the view that the structure of the machine or of the organism is an index of the performance that may be ex­pected from it” towards the end of his argument that ants and humans behave differently as a result of their physical body structures and changes. In light of more recent scholarship revealing, for instance, that ants have impressive brain-body mass ratios and are incredibly smart at a colony level (even at the level of starting wars with other colonies), and octopuses may also exhibit intelligence despite looking nothing like humans, should this position be revised? Moreover, Wiener goes on to write that “Theoretically, if we could build a machine whose mechanical structure duplicated human physiology, then we could have a machine whose intellectual capacities would duplicate those of human beings.” What might developments with artificial neural networks and GPUs have to say about this hypothesis?","As Dupuy and DeBevoise write, “The champions of artificial intelligence, exasperated by the overselling of the Perceptron, missed no opportunity to attack its mathematical formalization as insufficiently rigorous,” and that Minsky and Papert, effectively founding fathers of AI as we know it, were involved in these attacks. In contrast, almost no shortage of “overselling” occurs with many AI/ML developments, even if the results are lackluster in some aspects (e.g. ChatGPT hype despite numerous mistakes, generative art excitement despite lots of extra fingers and teeth, etc.). Are modern-day AI researchers truly “the successors of the cyberneticists” as briefly discussed in past lectures? Will today’s “overhype and overselling” die down as it did with the cyberneticists, or is there something different about today?"
Lindia Tjuatja,"It seems that a fundamental assumption (made by both McCulloch+Pitts as well as Wiener) is the all-or-nothing behavior of neurons. Has this been proven or disproven? If it's something that is ""close enough"" to all-or-nothing, is there a limit to how well we can approximate such behaviors through all-or-nothing digital means?","Wiener really bashes ants for their simplicity, but ants (and other animals, like birds and bees) have been looked at as models of ""swarm intelligence"". Why choose to base a model of intelligence on a single organism (as we define them), as opposed to larger systems of behavior? Is there a tradeoff between individual ""intellectual degrees of freedom"" and ""intelligent group acts"", and how do we strike a balance between the two?","In Dupuy's chapter, he mentions a split along the lines of the non-mentalists and the mentalists, a split that's still present today in the discussion of anthropomorphizing machine learning systems. How has this discussion changed over time, if at all? "
Dhananjay Ashok,To what extent should we be pursuing a form of Artificial Intelligence modeled on an understanding of the brain works?,Does anyone associate themeselves with Cybernetics today? What do they commonly believe in / speak about?,Should we abandon any theories or definitions of concepts like communication that rely on unobservables? Is there a better way to define these terms that still take into account some hazy internal process even if we cannot fully formalize it?
Patrick Fernandes," In ""The Mechanization of the Mind"", it is mentioned that a criticism by von Neumman and others was that the simplications employed in McCulloch’s axiomatized neuron could be too strong and missing degrees of freedom could be necessary to capture human-level intelligence. Is this still a reasonable hypothesis for current “artificial neurons”, or are we to believe (especially given the recent advances) that our simplified models have arecurrencell the necessary components to capture human-level intelligence?","The idea of “Nets with Circles” in McCulloch & Pitts paper seems to suggest that they believed “recurrence” was a necessary component to model intelligence. Given the recent advances with purely feed-forward architectures, can we safely assume that recurrence might not be necessary for human-level capabilities, or will we have to reintroduce recurrence as part of our models?","Wiener argues that “mechanical rigidity” of a biological organism has implications for it’s need for intelligence, with more rigid animals such as ants having little need for intelligence since they don’t need to learn through grow. Given that current AI systems are mostly “disembodied”, does this hypothesis even make sense today, or will future embodied AI systems need some for of “mechanical fluidity” in order to learn to the level of humans?"
Simran Khanuja,"With regards to the Dupuy reading: I don't quite understand why the McCulloch and Pitts model falls under the traditional definition of cybernetics. The initial parts of the reading focus on how “behaviour” of an object is what matters for intelligence, rather than its internal contents, but the neuron is biologically inspired. They touch upon the contradiction by saying that both approaches radicalize each other, but I don’t quite understand how",-,-