Timestamp,Name (First + Last) ,Email ID,Question 1,Question 2,Question 3
2/8/2023 16:28:53,Saujas Vaduguru,svadugur@andrew.cmu.edu,"Breiman describes the example of identifying the importance of variables using random forests with the case of hepatitis data, with variables 12 and 17 being found as the most important. Breiman describes verifications of this using other statistical models. Is there any other form of verification available for this? Maybe something based on real-world interventions, or a qualitative medical explanation for this? In general, how do we verify the faithfulness of the variable importances we get from algorithmic models?","Algorithmic methods offer insights when you can intervene on the (small amount of) data and retrain the model to observe changes, as is described in the permutation experiments that Breiman does. However, this is either impossible or extremely difficult with large-scale models like modern deep nets. Do they still offer some insights into the process, or is high predictive accuracy all we can get?","Mitchell writes ""This question covers a broad range of learning tasks..."" while Jordan, referring to many of the same tasks writes ""the bigger problem is that the use of this single, ill-defined acronym [of AI] prevents a clear understanding of the range of intellectual and commercial issues at play."" Is machine learning as Mitchell defines it (and in many ways II/IA as Jordan defines it) still to broad to shed light on the intellectual and commercial questions at play? "
2/9/2023 0:09:12,Patrick Fernandes,pfernand,"Breiman argues that “Using complex predictors maybe unpleasant, but the soundest path is to go for predictive accuracy first, then try to understand why”. Given the recent explosion in size of the most predicative models, can we still expect that the why will still be an answerable question, or is sacrificing the why a necessary condition for predictive accuracy?","Most of Mitchells’s current research questions seem to have found some form of answer in the last few years (and even some of the longer-terms). Given our current knowledge, what could we summarize as the most prominent research questions of the current age of ML?","Jordan argues for the creation of a new engineering discipline surrounding the interaction between AI systems and humans, with principles of analysis and design. But the lack of theory surrounding deep learning, the lack of interpretability of these models and ill-definition of the goal of AI, can we expect such a “principled engineering” discipline to emerge? "
2/9/2023 0:32:27,Conny Knieling,cok22@pitt.edu; cknielin@andrew.cmu.edu,Are what Breimann describes maybe problems of all sort of modelling (especially the case of mistaking the model for nature/what you are trying to model). It seems to me rather the problem that statisticians are not trained in philosophy of science and subscribe to a naive-sort of realism and second that the algorithmic modelling is not the way out but a methodological reflection of modelling itself (which in some cases may lead to a plurality of modelling/using data),"I used this article rather as a stepping stone for the following question, but this question popped up for me while reading and I wondered about it: Machine Learning succeeded in many different areas (speech recognition, vision, etc.) and I wonder whether there is something inherent to these areas that makes ML succeed here or whether the particular successes (as opposed to just being generally successful) are just random. Sure, ML enthusiasts would maybe say it is because these areas actually require the kind of learning ML is capable of, but I would not necessarily be convinced by that.",In what way does IA but especially II need a completely different framework and what would this look like?
2/9/2023 9:00:49,Emmy Liu,mengyan3,"1. In ""the two cultures"" essay, it seems like the author is mostly criticizing classical statisticians and comparing them with ML people, but I also think that ideal approaches would integrate the two. For instance, many ML researchers don't really do a good job (or any job) of hypothesis testing. Could the interaction of these two camps be expanded on more? ","2. I think the 'longer term research questions' section in Tom Mitchell's paper is very far-sighted and relevant. However I'm not sure what he means by ""computer perception"" in the last part, since it doesn't really specify. ","3. I agree with the goal of intelligence augmentation, but I think creating tools that automate parts of the creative process for humans can also lead to intelligence de-augmentation (e.g. kids using chatgpt to write essays and not learning how to write properly). I wonder if this could be discussed more? "
2/9/2023 9:53:12,Tzu-Ching Yen,tzuchiny,"In Beriman, how are data modeling and algorithmic modeling inherently different? It seems like a difference in philosophy but aren't both operationally the same in trying to come up with a function f(x) -> y. ",Beriman seems to paint a nice picture on the interpretability of random forests. Do we have recent studies that support or reject this optimism? ,Cox pointed out that considering the data-generating process may help when the training and testing sets are not iid. Are there concrete examples where knowing the different data-generating processes help resolving the shift. It seems hard to mathematically define any natural shift in data.
2/9/2023 10:01:11,Simran Khanuja,skhanuja@andrew.cmu.edu,"Regarding the Breiman reading: My interpretation may be wrong, but I don't quite agree with the data v/s algorithmic modeling distinction. Essentially all methods are trying to model data and the difference lies in hand-engineered features v/s learned features. Breiman refers to as random forests belonging to algorithmic modeling and decision trees to data, but the main difference IMO simply lies in accounting for stochasticity?","Regarding Breiman and Jordan: I believe that both are advocating for us to move in opposite directions. If we think about accuracy v/s interpretability, Breiman's focus is toward improving the former and Jordan's is towards improving the latter. As a community, what should we optimize for, especially given the ubiquitous use of ML today and its harmful repercussions in high-stake scenarios as Jordan discusses. ","Regarding Jordan: Jordan underscores the importance of studying data and highlights that a narrow focus on human-imitative AI would prevent diverse representation. However even if we study and understand data at scale, what are the best approaches we can use to model this data? Does he suggest we fall back to hand-designed features that are more interpretable too?"
2/9/2023 10:07:46,Ji Min Mun,jmun,Will machine learning lead to AI or is it a separate field all togther?,How do we bridge the gap between current practices of ML and the human-centric engineering view of the field as suggested by Michael Jordan?,How closely should we model brains to for models to learn or could we think of something different?